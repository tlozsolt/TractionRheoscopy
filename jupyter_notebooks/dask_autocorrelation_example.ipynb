{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelation with Dask, parallel \n",
    "\n",
    "The goal is to use dask to carry out spatial autocorrelation in parallel on multiple blocks.\n",
    "The keys functions are map_overlap and the autocorrelation function in data_analysis >> eshelby_inclusion\n",
    "\n",
    "Outline\n",
    "- Import libraries\n",
    "- Create synthetic data of 10 x 10 grid\n",
    "- Decide on auto-correlation shift vectors of, say 3x3\n",
    "- Compute autocorrelation acros the entire grid to check that dask splittig is working as expected\n",
    "- Create 2x2 chunks on the synth data\n",
    "- Map overlap, with added meta data information that the output array is not the same dimensions as the input array\n",
    "- Combine the output array to get the same output as the full autocorrelation across the entire grid. \n",
    "- Extend to 3D\n",
    "\n",
    "Extensions: make the code reusable so that in principle I could do the following as the input is still an array of scalars onto which I want to compute spatial correlations\n",
    "- The strain field is coarse grained (This should only change the rescale dimensions of the input and and rescale the shift vectors)\n",
    "- Scalar metrics of angular correlations: \n",
    "     - Correlate the angle of maximum principle strain direction projected in plane of the shear direction \n",
    "     - and similarily the angle out of plane of the shear direction \n",
    "     - I think its the three euler angles to rotate the strain ellipsoid with eignevalues in descending order (l1, l2, l3:\n",
    "       -  l1 - l3 -> x ~ direction of grid motion (maximum shear strain direction gets rotated onto grid displacement)\n",
    "       - vector normal to l1-l3 that is right handed coordinate system with z going up -> y ~ direction perpendicular to grid motion, in the plane of the grid \n",
    "       - l2 -> perpendicular to the grid, point up\n",
    "       - I think in the limit of linear elastic and simple shear, the strain ellipsoid would look like a needle pointing direction of applied strain\n",
    "       - In the limit of plane strain, the strain ellipsoid would be a thin disk in the plane of the shear plate. \n",
    "       - In both of these limiting cases, the autocorrelations should not decay spatially as the strain field is constant thorughout the body (in both magnitude and direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "import numba\n",
    "\n",
    "import sys\n",
    "sys.path.extend(['/Users/zsolt/Colloid_git/TractionRheoscopy'])\n",
    "from data_analysis import eshelby_inclusion as slb\n",
    "import tifffile\n",
    "from scipy.interpolate import griddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# create synthetic 10x10 grid\n",
    "# reshape gives the dimensions of the output grid, not the number of chunks\n",
    "A = np.arange(100).reshape((10,10))\n",
    "A_random = np.random.random_sample((10,10))\n",
    "\n",
    "# convert to dask array with 4 chunks total\n",
    "# also note that chunks specified are again the dimensions, not the number of chunks\n",
    "A_da = da.from_array(A, chunks=(5,5))\n",
    "A_random_da = da.from_array(A_random, chunks=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 800 B </td> <td> 200 B </td></tr>\n",
       "    <tr><th> Shape </th><td> (10, 10) </td> <td> (5, 5) </td></tr>\n",
       "    <tr><th> Count </th><td> 5 Tasks </td><td> 4 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> int64 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"170\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"60\" x2=\"120\" y2=\"60\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"120\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"60\" y1=\"0\" x2=\"60\" y2=\"120\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.000000,0.000000 120.000000,0.000000 120.000000,120.000000 0.000000,120.000000\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >10</text>\n",
       "  <text x=\"140.000000\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,60.000000)\">10</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<array, shape=(10, 10), dtype=int64, chunksize=(5, 5), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what does the 3x3 autocorrelation of this small array give?\n",
    "slb.spatialCorr(np.array([A]),np.array([A]),(0,3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "@numba.jit(nopython=True)\n",
    "def spatialCorr(A,B,k):\n",
    "    \"\"\"\n",
    "    Computes the spatial correlation of arrays A and B over the shift vectors with magnitude less than k\n",
    "\n",
    "    :param A: numpy array, possibly 3D\n",
    "    :param B: numpy array, possibly 3D\n",
    "    :param k: tuple, giving the max value of shift vectors to move B on top of A\n",
    "\n",
    "    return: numpy array of dimension 2k with values equal to the normalize autocorrelation (ie covariance)\n",
    "            of B shifted by ij, relative to A.\n",
    "    \"\"\"\n",
    "    out = np.zeros((2*k[0]+1, 2*k[1] + 1, 2*k[2] +1))\n",
    "    for kz in range(-1*k[0],k[0]+1):\n",
    "        for ky in range(-1*k[1],k[1]+1):\n",
    "            for kx in range(-1*k[2],k[2]+1):\n",
    "                if kz == 0:\n",
    "                    if ky > 0:\n",
    "                        if kx > 0:    a, b = A[:, ky:,  kx: ], B[:, :-1*ky, :-1*kx  ]\n",
    "                        elif kx < 0:  a, b = A[:, ky:, :kx  ], B[:, :-1*ky,  -1*kx: ]\n",
    "                        else:         a, b = A[:, ky:, :    ], B[:, :-1*ky, :       ]\n",
    "                    elif ky < 0:\n",
    "                        if kx > 0:    a, b = A[:, :ky,  kx: ], B[:, -1*ky:, :-1 * kx  ]\n",
    "                        elif kx < 0:  a, b = A[:, :ky, :kx  ], B[:, -1*ky:,  -1 * kx: ]\n",
    "                        else:         a, b = A[:, :ky, :    ], B[:, -1*ky:, :         ]\n",
    "                    else:\n",
    "                        if kx > 0:    a, b = A[:, :  ,  kx: ], B[:, :, :-1 * kx  ]\n",
    "                        elif kx < 0:  a, b = A[:, :  , :kx  ], B[:, :,  -1 * kx: ]\n",
    "                        else:         a, b = A[:, :  , :    ], B[:, :, :         ]\n",
    "\n",
    "                elif kz > 0:\n",
    "                    if ky > 0:\n",
    "                        if kx > 0:    a, b = A[kz:, ky:,  kx: ], B[:-1*kz, :-1*ky, :-1*kx  ]\n",
    "                        elif kx < 0:  a, b = A[kz:, ky:, :kx  ], B[:-1*kz, :-1*ky,  -1*kx: ]\n",
    "                        else:         a, b = A[kz:, ky:, :    ], B[:-1*kz, :-1*ky, :       ]\n",
    "                    elif ky < 0:\n",
    "                        if kx > 0:    a, b = A[kz:, :ky,  kx: ], B[:-1*kz, -1*ky:, :-1 * kx  ]\n",
    "                        elif kx < 0:  a, b = A[kz:, :ky, :kx  ], B[:-1*kz, -1*ky:,  -1 * kx: ]\n",
    "                        else:         a, b = A[kz:, :ky, :    ], B[:-1*kz, -1*ky:, :         ]\n",
    "                    else:\n",
    "                        if kx > 0:    a, b = A[kz:, :  ,  kx: ], B[:-1*kz, :, :-1 * kx  ]\n",
    "                        elif kx < 0:  a, b = A[kz:, :  , :kx  ], B[:-1*kz, :,  -1 * kx: ]\n",
    "                        else:         a, b = A[kz:, :  , :    ], B[:-1*kz, :, :         ]\n",
    "\n",
    "                else:\n",
    "                    if ky > 0:\n",
    "                        if kx > 0:    a, b = A[:kz, ky:,  kx: ], B[-1*kz:, :-1*ky, :-1*kx  ]\n",
    "                        elif kx < 0:  a, b = A[:kz, ky:, :kx  ], B[-1*kz:, :-1*ky,  -1*kx: ]\n",
    "                        else:         a, b = A[:kz, ky:, :    ], B[-1*kz:, :-1*ky, :       ]\n",
    "                    elif ky < 0:\n",
    "                        if kx > 0:    a, b = A[:kz, :ky,  kx: ], B[-1*kz:, -1*ky:, :-1 * kx  ]\n",
    "                        elif kx < 0:  a, b = A[:kz, :ky, :kx  ], B[-1*kz:, -1*ky:,  -1 * kx: ]\n",
    "                        else:         a, b = A[:kz, :ky, :    ], B[-1*kz:, -1*ky:, :         ]\n",
    "                    else:\n",
    "                        if kx > 0:    a, b = A[:kz, :  ,  kx: ], B[-1*kz:, :, :-1 * kx  ]\n",
    "                        elif kx < 0:  a, b = A[:kz, :  , :kx  ], B[-1*kz:, :,  -1 * kx: ]\n",
    "                        else:         a, b = A[:kz, :  , :    ], B[-1*kz:, :, :         ]\n",
    "                #out[kz, ky, kx] = (np.mean(a * b) - np.mean(a) * np.mean(b)) / (np.sqrt(np.var(a)) * np.sqrt(np.var(b)))\n",
    "                # that line is wrong...as the shift vector k is not the same as the array index.\n",
    "                out[kz + k[0], ky + k[1] ,kx + k[2]] = (np.mean(a * b) - np.mean(a) * np.mean(b)) / (np.sqrt(np.var(a)) * np.sqrt(np.var(b)))\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "out = slb.spatialCorr(np.array([A_random]),np.array([A_random]),(0,3,3)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(out, interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Comments on symmetry of auto- and cross-correlations\n",
    "\n",
    "Cross correlations have the property cross_AB(kx,ky) = cross_BA(-kx,-ky), without additional symmetry requirements on the signal.  \n",
    "\n",
    "However this symmetry is typically not even accidently visualized as it requires permuting the arguments. If you keep the arguement order fixed, by for example requiring that ideal eshelby always be the 2nd argument so crossCorrs(exptField, elasticSoln) means \"field is cross correlated with elastic solution,\" then you have not have any gauranteed symettries.  \n",
    "Even if the elastic field has symetry, the cross correlation with random field will be random. (check ?)\n",
    "Some hypotheses to check:\n",
    "> crossCorr(random, leftRightMirror) -> none  \n",
    " crossCorr(random, topDownMirro) -> none  \n",
    "crossCorr(random, twoMirrorPlanes) -> none    \n",
    "crossCorr(random, inversionCenterNoMirror) -> none    \n",
    "crossCorr(leftRightMirror, leftRightMirror) -> crossAB(kx,ky) = cross_AB(-x,ky)  \n",
    "crossCorr(leftRightMirror, topDownMirror) -> none  \n",
    "crossCorr(leftRightMirror, twoMirrors) -> crossAB(kx,ky) =crossAB(-kx,ky)  \n",
    "corssCorr(leftRightMirror, inversionCenter) -> crossAB(kx,ky) =  \n",
    "\n",
    "Hypothesis -> cross correlations will preserve only those symmetries present in *both* signals. \n",
    "\n",
    "\n",
    "Autocorrelations always an inversion center with no additional symmetry requirements on the signal:   \n",
    "> autoCorr_A(kx,ky) = autoCorr_A(-kx -ky) \n",
    "\n",
    "which is an easy consequence of the above cross correlation symmetry:  \n",
    "> autoCorr_A(kx,ky) = crossCorr_AA(kx,ky) =* crossCorr_AA(-kx,-ky) = autoCorr(-kx,-ky)which is an inversion symmetry...not a mirror.  \n",
    "\n",
    "where in the =* step involved trivally permute indices and apply the symmetry   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving onto map overlap in dask\n",
    "- set shift vector to be 1 and overlap to be 2.\n",
    "- note the example from docs.dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate onto grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import partial particle locations from Aidan's series of ~100k particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask\n",
    "path_partial = '/Users/zsolt/Colloid/DATA/tfrGel10212018x/tfrGel10212018A_shearRun10292018f/locations_stitch/partial_data_Aidan/'\n",
    "fName_frmt = 'shearRun10292018f_centerParticles_t{:02}.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try parallel using dask delayed\n",
    "def loadParticle(t):\n",
    "    pos_t = pd.read_hdf(path_partial + fName_frmt.format(t))\n",
    "    idx_t = pd.MultiIndex.from_product([[t],pos_t.index], names = ['frame', 'particle'] )\n",
    "    return pos_t.set_index(idx_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is almost perfect except I should specify the ip address for the cluster, and then use the\n",
    "# ip for all of these subprocesses dask clusters. \n",
    "posList = []\n",
    "with LocalCluster(n_workers=6, threads_per_worker=4, memory_limit='8Gb') as node, Client(node) as client:  \n",
    "    for t in range(40):\n",
    "        tmp = dask.delayed(loadParticle)(t)\n",
    "        posList.append(tmp)\n",
    "    pos = pd.concat(dask.compute(*posList))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pos.loc[([0,9],slice(None)),:][['x (um, imageStack)','y (um, imageStack)', 'z (um, imageStack)']];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import full positions and strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.7 s, sys: 10.1 s, total: 26.8 s\n",
      "Wall time: 26.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import dask\n",
    "\n",
    "hdf_stem= '/Users/zsolt/Colloid/DATA/tfrGel10212018x/tfrGel10212018A_shearRun10292018f/locations_stitch/'\n",
    "pos_fName = 'tfrGel10212018A_shearRun10292018f_sed_stitched_pandas.h5'\n",
    "strain_fName = 'tfrGel10212018A_shearRun10292018f_sed_strainTrajZeroRef.h5'\n",
    "pos = pd.read_hdf(hdf_stem + pos_fName)\n",
    "strain_ref0 = pd.read_hdf(hdf_stem + strain_fName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_analysis import static\n",
    "def computeStrain_dask(pos_df, tPair, output = 'strainTraj', pos_keys=None, verbose=False):\n",
    "    \"\"\"\n",
    "    Make LocalStrainTraj on a list of time points\n",
    "    tPairs = list(zip([0 for n in range(90)],[n for n in range(2,90)]))\n",
    "\n",
    "    This is a wrapper.  Mostly handles formatting the dataFrames.\n",
    "    \"\"\" \n",
    "    ref = tPair[0]\n",
    "    cur = tPair[1]\n",
    "    strain_traj = static.localStrain(pos_df,ref,cur,pos_keys=pos_keys)\n",
    "    #strain_traj = localStrain(pos_df, 0, 1, pos_keys = pos_keys)\n",
    "    strain_traj = strain_traj.stack().rename('({},{})'.format(ref,cur)).to_frame()\n",
    "    strain_traj.set_index(strain_traj.index.rename(['particle', 'values']), inplace=True)\n",
    "    if output == 'hdf':\n",
    "        raise KeyError('Saving strainTraj directly to hdf is not implemented yet')\n",
    "        #strain_fName = 'tfrGel10212018A_shearRun10292018f_sed_strainTraj_consecutive.h5'\n",
    "        #strain_traj.to_hdf(hdf_stem + strain_fName, '(0,t)', mode='a', format='table', data_columns=True)\n",
    "    elif output == 'strainTraj':\n",
    "        return strain_traj\n",
    "    else: raise KeyError('output {} not recognized'.format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "tPairs = list(zip([0 for n in range(39)],[n for n in range(1,40)]))\n",
    "subPosList = [pos.loc[([t[0],t[1]],slice(None)),:][['x (um, imageStack)','y (um, imageStack)', 'z (um, imageStack)']] for t in tPairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.utils - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/zsolt/.conda/envs/tractionRheoscopy/lib/python3.7/site-packages/distributed/utils.py\", line 655, in log_errors\n",
      "    yield\n",
      "  File \"/Users/zsolt/.conda/envs/tractionRheoscopy/lib/python3.7/site-packages/distributed/client.py\", line 1349, in _close\n",
      "    await self.scheduler_comm.close()\n",
      "concurrent.futures._base.CancelledError\n"
     ]
    },
    {
     "ename": "TimeoutError",
     "evalue": "timed out after 20 s.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2c5a9fd591b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mstrainList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrain_tmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstrainList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/tractionRheoscopy/lib/python3.7/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tractionRheoscopy/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, dsk, keys, restrictions, loose_restrictions, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\u001b[0m\n\u001b[1;32m   2724\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2725\u001b[0;31m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2726\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tractionRheoscopy/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   1991\u001b[0m                 \u001b[0mlocal_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1992\u001b[0;31m                 \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1993\u001b[0m             )\n",
      "\u001b[0;32m~/.conda/envs/tractionRheoscopy/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    832\u001b[0m             return sync(\n\u001b[0;32m--> 833\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m             )\n",
      "\u001b[0;32m~/.conda/envs/tractionRheoscopy/lib/python3.7/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tractionRheoscopy/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tractionRheoscopy/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2c5a9fd591b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mstrain_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrainFunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mstrainList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrain_tmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstrainList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/tractionRheoscopy/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tractionRheoscopy/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1429\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m         \u001b[0msync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"closed\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tractionRheoscopy/lib/python3.7/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallback_timeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"timed out after %s s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcallback_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: timed out after 20 s."
     ]
    }
   ],
   "source": [
    "with LocalCluster(n_workers=6, threads_per_worker=6, memory_limit='8Gb') as node, Client(node) as client:\n",
    "    strainList = []\n",
    "    \n",
    "    for n in range(len(tPairs)):\n",
    "        #sub_pos = pos.loc[([t[0],t[1]],slice(None)),:][['x (um, imageStack)','y (um, imageStack)', 'z (um, imageStack)']]\n",
    "        strainFunc = lambda n: computeStrain_dask(subPosList[n],tPairs[n])\n",
    "        strain_tmp = dask.delayed(strainFunc)(n)\n",
    "        strainList.append(strain_tmp)\n",
    "    tmp = dask.compute(*strainList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 4), (3, 5), (3, 6), (3, 7), (3, 8)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a simple function to make a list of pairs with a given ref and cur configuration and all time points between them\n",
    "def mkPair(ref,cur):\n",
    "    out = []\n",
    "    for t in range(1,cur-ref +1):\n",
    "        out.append((ref, ref +t))\n",
    "    return out\n",
    "mkPair(3,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on full data set this takes...up a lot of ram\n",
    "# 11Gb to load pos and strain ref0\n",
    "# 13Gb to form subPosList. \n",
    "# default dask dash board at http://localhost:8787/status\n",
    "\n",
    "#specialStrainPts = [(3,8),(7,22),(8,10),(22,23),(23,26)]\n",
    "specialStrainPts = [(3,8)]\n",
    "flatten = lambda t: [item for sublist in t for item in sublist]\n",
    "#tPairList = [item for sublist in [mkPair(t[0],t[1]) for t in specialStrainPts] for item in sublist]\n",
    "\n",
    "#specialStrainPts = [(3,8),(7,22),(8,10),(22,23),(23,26)]\n",
    "tPairs = flatten([mkPair(t[0],t[1]) for t in specialStrainPts])\n",
    "subPosList = [pos.loc[([t[0],t[1]],slice(None)),:][['x (um, imageStack)','y (um, imageStack)', 'z (um, imageStack)']] for t in tPairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 4), (3, 5), (3, 6), (3, 7), (3, 8)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tPairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "with LocalCluster(n_workers=2, threads_per_worker=6, memory_limit='16Gb') as node, Client(node) as client:\n",
    "    strainList = []\n",
    "    for n in range(len(tPairs)):\n",
    "        strainFunc = lambda n: computeStrain_dask(subPosList[n],tPairs[n])\n",
    "        strain_tmp = dask.delayed(strainFunc)(n)\n",
    "        strainList.append(strain_tmp)\n",
    "    tmp = dask.compute(*strainList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try simple multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 758 ms, sys: 7.94 s, total: 8.69 s\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#This work work 1.5Gb per worker...very well.  \n",
    "def strainFunc(n):\n",
    "    return computeStrain_dask(subPosList[n],tPairs[n])\n",
    "\n",
    "p = multiprocessing.Pool(5)\n",
    "strainList = p.map(strainFunc,[n for n in range(len(tPairs))])\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 4), (3, 5), (3, 6), (3, 7), (3, 8)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tPairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt at serialization of tmp to avoid memory overhead\n",
    "# this was ludicrous fast for fixed format \n",
    "# the only thing I would like is to be able to slice for a specific particle id, but perhaps this is asking for too much\n",
    "path_strainSerial = '/Users/zsolt/Colloid/DATA/tfrGel10212018x/tfrGel10212018A_shearRun10292018f/locations_stitch/'\n",
    "fName = 'specialStrainPts_loading_tables.h5'\n",
    "with pd.HDFStore(path_strainSerial + fName) as store:\n",
    "    for n in range(len(strainList)):\n",
    "    #for n in range(2):\n",
    "        df = strainList[n]\n",
    "        key = 'ref{:02}_cur{:02}'.format(tPairs[n][0],tPairs[n][1])\n",
    "        store.append(key, df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/ref03_cur08',\n",
       " '/ref07_cur22',\n",
       " '/ref08_cur10',\n",
       " '/ref22_cur23',\n",
       " '/ref23_cur26']"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store = pd.HDFStore(path_strainSerial + fName)\n",
    "store.keys()\n",
    "#store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "out = []\n",
    "for t in store.keys():\n",
    "    out.append(store.select(t,\"particle=74955\"))\n",
    "#pd.concat(out,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/ref00_cur01',\n",
       " '/ref00_cur02',\n",
       " '/ref00_cur03',\n",
       " '/ref00_cur04',\n",
       " '/ref00_cur05',\n",
       " '/ref00_cur06',\n",
       " '/ref00_cur07',\n",
       " '/ref00_cur08',\n",
       " '/ref00_cur09',\n",
       " '/ref00_cur10',\n",
       " '/ref00_cur11',\n",
       " '/ref00_cur12',\n",
       " '/ref00_cur13',\n",
       " '/ref00_cur14',\n",
       " '/ref00_cur15',\n",
       " '/ref00_cur16',\n",
       " '/ref00_cur17',\n",
       " '/ref00_cur18',\n",
       " '/ref00_cur19',\n",
       " '/ref00_cur20',\n",
       " '/ref00_cur21',\n",
       " '/ref00_cur22',\n",
       " '/ref00_cur23',\n",
       " '/ref00_cur24',\n",
       " '/ref00_cur25',\n",
       " '/ref00_cur26',\n",
       " '/ref00_cur27',\n",
       " '/ref00_cur28',\n",
       " '/ref00_cur29',\n",
       " '/ref00_cur30',\n",
       " '/ref00_cur31',\n",
       " '/ref00_cur32',\n",
       " '/ref00_cur33',\n",
       " '/ref00_cur34',\n",
       " '/ref00_cur35',\n",
       " '/ref00_cur36',\n",
       " '/ref00_cur37',\n",
       " '/ref00_cur38',\n",
       " '/ref00_cur39']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.select('ref00_cur11','particle=74955')\n",
    "store.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can I load the entire pyTables into memory? \n",
    "# this does explore the memory at least on activity monitor, but it does not lead to memory pressure which is confusing.\n",
    "# I think if it was wrapped in a subprocess it would work fine.\n",
    "# like this >> https://www.confessionsofadataguy.com/solving-the-memory-hungry-pandas-concat-problem/\n",
    "# but no parquet\n",
    "# also note that this is exactly how pandas reccomends you read the hdfstroe into memory\n",
    "# >> https://pandas.pydata.org/pandas-docs/stable/user_guide/cookbook.html#cookbook-csv-multiple-files\n",
    "# see line 191, reading multiple files to create a single dataFrame \n",
    "# or some chunksize parameter? I think that is best handled by concatenating each key, one by one. \n",
    "\n",
    "# no wrapping\n",
    "#allStrain = pd.concat([pd.read_hdf(path_strainSerial + 'strainList_tablesFormat_copy.h5', key) for key in store.keys()],axis=1)\n",
    "\n",
    "# an attempt at wrapping. although this is still using pd concat so I am not sure I have really gained anything. \n",
    "# I want it to allocate enough swap memory for a single key, not all the keys. \n",
    "#with pd.HDFStore(path_strainSerial + fName) as store:\n",
    "#    allStrain = pd.concat([pd.read_hdf(path_strainSerial + fName, key) for key in store.keys()],axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what would this do?\n",
    "# I think this works. No memory jump\n",
    "#fName_copy = 'strainList_tablesFormat.h5'\n",
    "with pd.HDFStore(path_strainSerial + fName) as store:\n",
    "    key0 = store.keys()[0]\n",
    "    specialStrain = store.select(key0)\n",
    "    for n in range(1,len(store.keys())):\n",
    "        #print(n)\n",
    "        key = store.keys()[n]\n",
    "        new_df = store.select(key)\n",
    "        # This may actually work without axis=1, but I am not sure why. \n",
    "        #allStrain2 = pd.concat([allStrain,new_df])\n",
    "        specialStrain = pd.concat([specialStrain,new_df],axis=1)\n",
    "    #allStrain = pd.concat([pd.read_hdf(path_strainSerial + fName, key) for key in store.keys()],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'specialStrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4932e6f29cf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspecialStrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'specialStrain' is not defined"
     ]
    }
   ],
   "source": [
    "specialStrain.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.close\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# get two small positions\n",
    "pos0 = pd.read_hdf(path_partial + fName_frmt.format(0))\n",
    "idx0 = pd.MultiIndex.from_product([[0],pos0.index],names = ['frame','particle'])\n",
    "pos = pos0.set_index(idx0)\n",
    "for t in range(1,10):\n",
    "    pos_t = pd.read_hdf(path_partial + fName_frmt.format(t))\n",
    "    idx_t = pd.MultiIndex.from_product([[t],pos_t.index], names = ['frame', 'particle'] )\n",
    "    pos_t = pos_t.set_index(idx_t)\n",
    "    pos = pd.concat([pos,pos_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>(3,8)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>particle</th>\n",
       "      <th>values</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">12</th>\n",
       "      <th>D2_min</th>\n",
       "      <td>0.158916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exx</th>\n",
       "      <td>0.000656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exy</th>\n",
       "      <td>-0.002402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exz</th>\n",
       "      <td>0.006679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eyy</th>\n",
       "      <td>-0.006326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">983130</th>\n",
       "      <th>ezz</th>\n",
       "      <td>0.036013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rxy</th>\n",
       "      <td>-0.005947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rxz</th>\n",
       "      <td>0.003773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ryz</th>\n",
       "      <td>0.015374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nnb count</th>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10518640 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       (3,8)\n",
       "particle values             \n",
       "12       D2_min     0.158916\n",
       "         exx        0.000656\n",
       "         exy       -0.002402\n",
       "         exz        0.006679\n",
       "         eyy       -0.006326\n",
       "...                      ...\n",
       "983130   ezz        0.036013\n",
       "         rxy       -0.005947\n",
       "         rxz        0.003773\n",
       "         ryz        0.015374\n",
       "         nnb count  9.000000\n",
       "\n",
       "[10518640 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strainList[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "tPairs = list(zip([0 for n in range(9)],[n for n in range(2,9)]))\n",
    "strain_traj = static.makeLocalStrainTraj(pos,tPairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'strain_traj' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-9bbd7306033a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# compute the strain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstrain_traj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'strain_traj' is not defined"
     ]
    }
   ],
   "source": [
    "# compute the strain\n",
    "strain_traj.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### interpolate the strain value onto a grid using the reference particle configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the index of complete particle trajectories\n",
    "# note the use of .xs('exx',level='values') is just reduce the multiplicity of \n",
    "# particle indices repeated in multiindex for each value. By speccing a single but arbitrary choice the particle ids\n",
    "# are listed only once when using get_level_values\n",
    "strain_traj = strainList[4]\n",
    "\n",
    "#idx_traj = strain_traj.dropna().xs('exx',level='values').index.get_level_values('particle')\n",
    "idx_traj = strain_traj.dropna().xs('exx',level='values')[strain_traj.dropna().xs('nnb count',level='values') > 9].dropna().index.get_level_values('particle')\n",
    "idx_refConfig = pos.xs(3,level='frame').index\n",
    "idx = idx_refConfig.intersection(idx_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([    56,     66,     68,     69,     70,     77,     78,     83,\n",
       "                85,     92,\n",
       "            ...\n",
       "            982990, 982994, 983045, 983059, 983068, 983073, 983074, 983075,\n",
       "            983076, 983077],\n",
       "           dtype='int64', name='particle', length=930540)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='(3,8)', ylabel='Count'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(strain_traj.xs('exz', level='values').loc[idx]['(3,8)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    907539.000000\n",
       "mean          0.001688\n",
       "std           0.007791\n",
       "min          -0.092788\n",
       "25%          -0.003132\n",
       "50%           0.001685\n",
       "75%           0.006500\n",
       "max           0.140883\n",
       "Name: (3,8), dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strain_traj.xs('exz', level='values').loc[idx]['(3,8)'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1166901847251969,\n",
       " 0.17817131781481274,\n",
       " 0.22009171772315778,\n",
       " 0.3402235606838048]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_tmp = strain_traj.xs('exz', level='values').loc[idx]\n",
    "out=[]\n",
    "for t in [4,5,6,8]:\n",
    "    out.append(200*_tmp['(3,{})'.format(t)].describe()['mean'])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>x (um, imageStack)</th>\n",
       "      <th>y (um, imageStack)</th>\n",
       "      <th>z (um, imageStack)</th>\n",
       "      <th>x_std</th>\n",
       "      <th>y_std</th>\n",
       "      <th>z_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame</th>\n",
       "      <th>particle</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>23.480112</td>\n",
       "      <td>2.221875</td>\n",
       "      <td>27.385583</td>\n",
       "      <td>0.160625</td>\n",
       "      <td>0.149919</td>\n",
       "      <td>0.139626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.531264</td>\n",
       "      <td>2.180390</td>\n",
       "      <td>27.351286</td>\n",
       "      <td>0.121123</td>\n",
       "      <td>0.120859</td>\n",
       "      <td>0.108598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.789111</td>\n",
       "      <td>2.119240</td>\n",
       "      <td>27.275850</td>\n",
       "      <td>0.130098</td>\n",
       "      <td>0.134635</td>\n",
       "      <td>0.117372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.408522</td>\n",
       "      <td>2.436315</td>\n",
       "      <td>27.277841</td>\n",
       "      <td>0.110703</td>\n",
       "      <td>0.114330</td>\n",
       "      <td>0.101162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.347537</td>\n",
       "      <td>2.748365</td>\n",
       "      <td>27.335966</td>\n",
       "      <td>0.134831</td>\n",
       "      <td>0.134550</td>\n",
       "      <td>0.121837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">89</th>\n",
       "      <th>1489977</th>\n",
       "      <td>200.492249</td>\n",
       "      <td>221.169243</td>\n",
       "      <td>71.848828</td>\n",
       "      <td>0.121115</td>\n",
       "      <td>0.122348</td>\n",
       "      <td>0.104224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489978</th>\n",
       "      <td>187.204307</td>\n",
       "      <td>202.418158</td>\n",
       "      <td>83.305471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489979</th>\n",
       "      <td>188.845862</td>\n",
       "      <td>225.415862</td>\n",
       "      <td>83.684483</td>\n",
       "      <td>1.279382</td>\n",
       "      <td>0.922309</td>\n",
       "      <td>1.188493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489980</th>\n",
       "      <td>193.989494</td>\n",
       "      <td>194.780281</td>\n",
       "      <td>83.924158</td>\n",
       "      <td>119852.822302</td>\n",
       "      <td>111242.080747</td>\n",
       "      <td>128126.585762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489981</th>\n",
       "      <td>186.063189</td>\n",
       "      <td>201.029539</td>\n",
       "      <td>85.103917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87508017 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                x (um, imageStack)  y (um, imageStack)  z (um, imageStack)  \\\n",
       "frame particle                                                               \n",
       "0     0                  23.480112            2.221875           27.385583   \n",
       "      1                  31.531264            2.180390           27.351286   \n",
       "      2                  37.789111            2.119240           27.275850   \n",
       "      3                  39.408522            2.436315           27.277841   \n",
       "      4                  35.347537            2.748365           27.335966   \n",
       "...                            ...                 ...                 ...   \n",
       "89    1489977           200.492249          221.169243           71.848828   \n",
       "      1489978           187.204307          202.418158           83.305471   \n",
       "      1489979           188.845862          225.415862           83.684483   \n",
       "      1489980           193.989494          194.780281           83.924158   \n",
       "      1489981           186.063189          201.029539           85.103917   \n",
       "\n",
       "                        x_std          y_std          z_std  \n",
       "frame particle                                               \n",
       "0     0              0.160625       0.149919       0.139626  \n",
       "      1              0.121123       0.120859       0.108598  \n",
       "      2              0.130098       0.134635       0.117372  \n",
       "      3              0.110703       0.114330       0.101162  \n",
       "      4              0.134831       0.134550       0.121837  \n",
       "...                       ...            ...            ...  \n",
       "89    1489977        0.121115       0.122348       0.104224  \n",
       "      1489978             NaN            NaN            NaN  \n",
       "      1489979        1.279382       0.922309       1.188493  \n",
       "      1489980   119852.822302  111242.080747  128126.585762  \n",
       "      1489981             NaN            NaN            NaN  \n",
       "\n",
       "[87508017 rows x 6 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#strain_traj.dropna().xs('exz',level='values')[strain_traj.dropna().xs('nnb count',level='values') > 9].dropna().index.get_level_values('particle')\n",
    "pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for interpolation we need a list of:\n",
    "- points (x,y,z) coordinates \n",
    "- values of the quantitiy, in this case one of the strain components\n",
    "- and the grid size and mesh spacing onto which the interpolation will occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate the strain data with a given mesh spacing\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "posKeyList = ['{} (um, imageStack)'.format(x) for x in ['z','y','x']]\n",
    "\n",
    "# get the points and note that the numpy output will be in whatever column order you called the columns\n",
    "pts_zyx = pos.xs(3,level='frame').loc[idx][posKeyList].to_numpy()\n",
    "\n",
    "# get exz comp of strain. note that you have to take cross section prior to loc otherwsie it crashes. \n",
    "# be careful taking loc on multiindex array. you can do it but you have to specfiy the multindex and not simply\n",
    "# the particle index as if there were no other depth. \n",
    "\n",
    "vals_exz = strain_traj.xs('exz', level='values').loc[idx]['(3,8)'].to_numpy()\n",
    "\n",
    "grid_z, grid_y, grid_x = np.mgrid[27:86:0.5, 0:235:0.5, 0:235:0.5 ]\n",
    "interp= griddata(pts_zyx, vals_exz, (grid_z, grid_y, grid_x), method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93806320061996"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what fraction is filled with interpolated values? \n",
    "# The fact that this is not 100% is due to the grid exceeding sampling domain specified in pts_xyz\n",
    "# I am a little surprised though that this is over 30% unfilled by \n",
    "# picking the bounds be max and mins of xyz components seprately.\n",
    "# this filling fraction does not depend on the sampling mesh, which is good. I think its just a boundary effect\n",
    "np.count_nonzero(~np.isnan(interp))/interp.flatten().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "raw_max, raw_min = np.percentile(interp[~np.isnan(interp)],99.9), np.percentile(interp[~np.isnan(interp)],0.1)\n",
    "\n",
    "tmp = np.nan_to_num(interp, nan=1.1*raw_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028557038675005284"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.max()\n",
    "raw_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize with pyFiji\n",
    "from particleLocating import pyFiji\n",
    "import tifffile\n",
    "import pyperclip\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'particleLocating.pyFiji' from '/Users/zsolt/Colloid_git/TractionRheoscopy/particleLocating/pyFiji.py'>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(pyFiji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def send2Fiji(arrayList, wdir =None ,metaData=None):\n",
    "    \"\"\" \n",
    "  This function takes a nparray or a list of np.array\n",
    "  [+] writes each array to tif in wdir using a tmp.tif\n",
    "  [+] creates an text object that contains a fiji macro\n",
    "  [+] copies the macro to the system keyboard.\n",
    "  After it runs, if you go to fiji and press fn-F1, fiji will take the text on system clipboard and run it as macro\n",
    "  This last step is accomplished by creating a simple macro and mapping it it to F1 using fiji shortcut\n",
    "  I also created a macro to close all windows in fiji and mapped that to F2.\n",
    "    \"\"\"\n",
    "    if wdir is None: wdir = '/Volumes/TFR/tfrGel10212018A_shearRun10292018f/pyFiji/'\n",
    "    def send2FijiSingleArray(nparray,index):\n",
    "        dataStr = str(datetime.date.today())\n",
    "        #path = flatField.array2tif(nparray,wdir+'/tmp_'+ dataStr + str(index)+'.tif',metaData=metaData)\n",
    "        path = wdir+'tmp_{}.tif'.format(index)\n",
    "        tifffile.imwrite(path,nparray)\n",
    "        return 'open(\"'+ path +'\");\\n'\n",
    "    macroText = ''\n",
    "    if type(arrayList) == np.ndarray:\n",
    "        macroText += send2FijiSingleArray(arrayList,0)\n",
    "    elif type(arrayList) == list:\n",
    "        for n in range(len(arrayList)): \n",
    "            macroText += send2FijiSingleArray(arrayList[n],n)\n",
    "    pyperclip.copy(macroText)\n",
    "    print(\"Images saved to tif and copied to system clipboard.\")\n",
    "    return macroText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images saved to tif and copied to system clipboard.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'open(\"/Volumes/TFR/tfrGel10212018A_shearRun10292018f/pyFiji/tmp_0.tif\");\\n'"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "send2Fiji(pyFiji.recastImage(tmp,{'min':3*raw_min,'max':3*raw_max}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 713.90 MB </td> <td> 15.62 MB </td></tr>\n",
       "    <tr><th> Shape </th><td> (295, 550, 550) </td> <td> (125, 125, 125) </td></tr>\n",
       "    <tr><th> Count </th><td> 75 Tasks </td><td> 75 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> float64 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"217\" height=\"207\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"47\" y2=\"37\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"27\" x2=\"47\" y2=\"65\" />\n",
       "  <line x1=\"10\" y1=\"54\" x2=\"47\" y2=\"92\" />\n",
       "  <line x1=\"10\" y1=\"81\" x2=\"47\" y2=\"119\" />\n",
       "  <line x1=\"10\" y1=\"109\" x2=\"47\" y2=\"146\" />\n",
       "  <line x1=\"10\" y1=\"120\" x2=\"47\" y2=\"157\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"26\" y2=\"136\" />\n",
       "  <line x1=\"42\" y1=\"32\" x2=\"42\" y2=\"152\" />\n",
       "  <line x1=\"47\" y1=\"37\" x2=\"47\" y2=\"157\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 47.86096256684492,37.86096256684492 47.86096256684492,157.86096256684493 10.0,120.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"146\" y2=\"16\" />\n",
       "  <line x1=\"42\" y1=\"32\" x2=\"162\" y2=\"32\" />\n",
       "  <line x1=\"47\" y1=\"37\" x2=\"167\" y2=\"37\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"47\" y2=\"37\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"37\" y1=\"0\" x2=\"75\" y2=\"37\" />\n",
       "  <line x1=\"64\" y1=\"0\" x2=\"102\" y2=\"37\" />\n",
       "  <line x1=\"91\" y1=\"0\" x2=\"129\" y2=\"37\" />\n",
       "  <line x1=\"119\" y1=\"0\" x2=\"156\" y2=\"37\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"167\" y2=\"37\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 167.86096256684493,37.86096256684492 47.86096256684492,37.86096256684492\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"47\" y1=\"37\" x2=\"167\" y2=\"37\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"47\" y1=\"65\" x2=\"167\" y2=\"65\" />\n",
       "  <line x1=\"47\" y1=\"92\" x2=\"167\" y2=\"92\" />\n",
       "  <line x1=\"47\" y1=\"119\" x2=\"167\" y2=\"119\" />\n",
       "  <line x1=\"47\" y1=\"146\" x2=\"167\" y2=\"146\" />\n",
       "  <line x1=\"47\" y1=\"157\" x2=\"167\" y2=\"157\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"47\" y1=\"37\" x2=\"47\" y2=\"157\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"75\" y1=\"37\" x2=\"75\" y2=\"157\" />\n",
       "  <line x1=\"102\" y1=\"37\" x2=\"102\" y2=\"157\" />\n",
       "  <line x1=\"129\" y1=\"37\" x2=\"129\" y2=\"157\" />\n",
       "  <line x1=\"156\" y1=\"37\" x2=\"156\" y2=\"157\" />\n",
       "  <line x1=\"167\" y1=\"37\" x2=\"167\" y2=\"157\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"47.86096256684492,37.86096256684492 167.86096256684493,37.86096256684492 167.86096256684493,157.86096256684493 47.86096256684492,157.86096256684493\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"107.860963\" y=\"177.860963\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >550</text>\n",
       "  <text x=\"187.860963\" y=\"97.860963\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,187.860963,97.860963)\">550</text>\n",
       "  <text x=\"18.930481\" y=\"158.930481\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,18.930481,158.930481)\">295</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<array, shape=(295, 550, 550), dtype=float64, chunksize=(125, 125, 125), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to dask array and set chunk size. \n",
    "import dask\n",
    "chunk_zyx_um = np.array((25,25,25))\n",
    "um2mesh = np.array((0.2,0.2,0.2))\n",
    "chunk_zyx_interp = chunk_zyx_um/um2mesh\n",
    "tmp_da = dask.array.from_array(tmp,chunks=chunk_zyx_interp)\n",
    "tmp_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50, 50, 50])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map blocks \n",
    "# I am not currently sure how spatialCorr is going to treat the nan vlaues or what I should map those to before applying map blocks\n",
    "#A_3d = da.arange(75**3).reshape((75,75,75)).rechunk(chunks=(15,15,15))\n",
    "from data_analysis import eshelby_inclusion\n",
    "k_um = np.array((10,10,10))\n",
    "k_px = k_um/um2mesh\n",
    "k_px.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "autoCorr_3d = lambda x: eshelby_inclusion.spatialCorr_daskWrapper(x, x, k_px.astype(int), corrFunc='forLoop', padOut=True)\n",
    "# n_workers=10, smaller array, I am running at 50% total cpu and about 500mb of ram per process.\n",
    "# did not finish after 12 hours so I killed it. \n",
    "with LocalCluster(n_workers=10, threads_per_worker=6, memory_limit='5Gb') as node, Client(node) as client:\n",
    "    out_overlap3D = tmp_da.map_overlap(autoCorr_3d, depth=40, dtype='float32', boundary='none').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(295, 550, 550)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.4 s, sys: 1.57 s, total: 48.9 s\n",
      "Wall time: 48.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mesh_dzyx_um = np.array((0.5,0.5,0.5))\n",
    "posKeyList = ['{} (um, imageStack)'.format(x) for x in ['z','y','x']]\n",
    "\n",
    "# get the points and note that the numpy output will be in whatever column order you called the columns\n",
    "pts_zyx = pos.xs(3,level='frame').loc[idx][posKeyList].to_numpy()\n",
    "\n",
    "# get exz comp of strain. note that you have to take cross section prior to loc otherwsie it crashes. \n",
    "# be careful taking loc on multiindex array. you can do it but you have to specfiy the multindex and not simply\n",
    "# the particle index as if there were no other depth. \n",
    "\n",
    "vals_exz = strain_traj.xs('exz', level='values').loc[idx]['(3,8)'].to_numpy()\n",
    "\n",
    "grid_z, grid_y, grid_x = np.mgrid[27:86:mesh_dzyx_um[0], 1:234:mesh_dzyx_um[1], 1:234:mesh_dzyx_um[2] ]\n",
    "interp = griddata(pts_zyx, vals_exz, (grid_z, grid_y, grid_x), method='linear')\n",
    "\n",
    "# clip any boundaries to 0\n",
    "tmp = np.nan_to_num(interp, nan=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 466, 466)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp2 = np.zeros((120,460,460))\n",
    "tmp2[1:tmp.shape[0]+1,:,:] = tmp[:,3:tmp.shape[2]-3,3:tmp.shape[2]-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3., 10., 10.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp2.shape/np.array((40,46,46))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 39, 210, 210]), array([ 79, 256, 256]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chunk_dzyx = np.array((20,23,23)) # 20 um chunk\n",
    "chunk_px = chunk_dzyx/mesh_dzyx_um\n",
    "l = (tmp.shape/np.array(2) - chunk_px/2).astype(int)\n",
    "r = (tmp.shape/np.array(2) + chunk_px/2).astype(int)\n",
    "l,r "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profile a single chunk, \"manually\" without dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 677.12 kB </td> <td> 677.12 kB </td></tr>\n",
       "    <tr><th> Shape </th><td> (40, 46, 46) </td> <td> (40, 46, 46) </td></tr>\n",
       "    <tr><th> Count </th><td> 1 Tasks </td><td> 1 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> float64 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"241\" height=\"231\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"71\" y2=\"61\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"120\" x2=\"71\" y2=\"181\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"71\" y1=\"61\" x2=\"71\" y2=\"181\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 71.38107416879797,61.38107416879796 71.38107416879797,181.38107416879797 10.0,120.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"71\" y1=\"61\" x2=\"191\" y2=\"61\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"71\" y2=\"61\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"191\" y2=\"61\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 191.38107416879797,61.38107416879796 71.38107416879797,61.38107416879796\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"71\" y1=\"61\" x2=\"191\" y2=\"61\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"71\" y1=\"181\" x2=\"191\" y2=\"181\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"71\" y1=\"61\" x2=\"71\" y2=\"181\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"191\" y1=\"61\" x2=\"191\" y2=\"181\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"71.38107416879797,61.38107416879796 191.38107416879797,61.38107416879796 191.38107416879797,181.38107416879797 71.38107416879797,181.38107416879797\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"131.381074\" y=\"201.381074\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >46</text>\n",
       "  <text x=\"211.381074\" y=\"121.381074\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,211.381074,121.381074)\">46</text>\n",
       "  <text x=\"30.690537\" y=\"170.690537\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,30.690537,170.690537)\">40</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<array, shape=(40, 46, 46), dtype=float64, chunksize=(40, 46, 46), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cut out the chunk into a separate array\n",
    "tmp_middleChunk = tmp[l[0]:r[0],l[1]:r[1], l[2]:r[2]]\n",
    "#tmp_da = dask.array.from_array(tmp_middleChunk,chunks=chunk_zyx_interp)\n",
    "chunk_da = dask.array.from_array(tmp_middleChunk,chunks=(40,46,46))\n",
    "\n",
    "k_um = np.array((9,10,10))\n",
    "k_px = k_um/mesh_dzyx_um\n",
    "k_px.astype(int)\n",
    "chunk_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.2 s, sys: 115 ms, total: 27.3 s\n",
      "Wall time: 27.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# took 30 secs on 1 thread...there is clearly something wrong with dask and map blocks. \n",
    "autoCorr_3d = lambda x: slb.spatialCorr_daskWrapper(x, x, k_px.astype(int), corrFunc='forLoop', padOut=False)\n",
    "out_chunk = autoCorr_3d(tmp_middleChunk)\n",
    "#with LocalCluster(n_workers=15, threads_per_worker=6, memory_limit='2Gb') as node, Client(node) as client:\n",
    "#    out_overlap3D = tmp_da.map_overlap(autoCorr_3d, depth=20, dtype='float32',chunks=np.array((2*k_px[0]+1, 2*k_px[1]+1, 2*k_px[2]+1)).astype(int)).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# how much time does overlap add? takes about 2 min\n",
    "overlap_px = 20\n",
    "tmp_overlap = tmp[l[0]-10:r[0]+10,l[1]-10:r[1]+10, l[2]-10:r[2]+10]\n",
    "autoCorr_3d = lambda x: slb.spatialCorr_daskWrapper(x, x, k_px.astype(int), corrFunc='forLoop', padOut=False)\n",
    "out_chunkOverlap = autoCorr_3d(tmp_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.24 s, sys: 313 ms, total: 5.56 s\n",
      "Wall time: 34.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# what if we use mapblocks on a single chunk? \n",
    "\n",
    "# took 30 secs on 1 thread...there is clearly something wrong with dask and map blocks. \n",
    "autoCorr_3d = lambda x: slb.spatialCorr_daskWrapper(x, x, k_px.astype(int), corrFunc='forLoop', padOut=False)\n",
    "#out_chunk = autoCorr_3d(tmp_middleChunk)\n",
    "with LocalCluster(n_workers=1, threads_per_worker=6, memory_limit='2Gb') as node, Client(node) as client:\n",
    "    out_overlap3D = chunk_da.map_blocks(autoCorr_3d, dtype='float32').astype(int).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map blocks on 4 chunks with 4 cores\n",
    "_n = np.array((1,1,1)).astype(int)\n",
    "n = _n*chunk_px.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task was destroyed but it is pending!\n",
      "task: <Task pending coro=<HTTP1ServerConnection._server_request_loop() running at /Users/zsolt/.conda/envs/tractionRheoscopy/lib/python3.7/site-packages/tornado/http1connection.py:817> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x7f843479c3d0>()]> cb=[IOLoop.add_future.<locals>.<lambda>() at /Users/zsolt/.conda/envs/tractionRheoscopy/lib/python3.7/site-packages/tornado/ioloop.py:690]>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending coro=<HTTP1ServerConnection._server_request_loop() running at /Users/zsolt/.conda/envs/tractionRheoscopy/lib/python3.7/site-packages/tornado/http1connection.py:817> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x7f7d08238350>()]> cb=[IOLoop.add_future.<locals>.<lambda>() at /Users/zsolt/.conda/envs/tractionRheoscopy/lib/python3.7/site-packages/tornado/ioloop.py:690]>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending coro=<RequestHandler._execute() running at /Users/zsolt/.conda/envs/tractionRheoscopy/lib/python3.7/site-packages/tornado/web.py:1703> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x7f84128d7190>()]> cb=[_HandlerDelegate.execute.<locals>.<lambda>() at /Users/zsolt/.conda/envs/tractionRheoscopy/lib/python3.7/site-packages/tornado/web.py:2333]>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending coro=<HTTP1ServerConnection._server_request_loop() running at /Users/zsolt/.conda/envs/tractionRheoscopy/lib/python3.7/site-packages/tornado/http1connection.py:817> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x7f8455845410>()]> cb=[IOLoop.add_future.<locals>.<lambda>() at /Users/zsolt/.conda/envs/tractionRheoscopy/lib/python3.7/site-packages/tornado/ioloop.py:690]>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending coro=<RequestHandler._execute() running at /Users/zsolt/.conda/envs/tractionRheoscopy/lib/python3.7/site-packages/tornado/web.py:1703> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x7f845581ffd0>()]> cb=[_HandlerDelegate.execute.<locals>.<lambda>() at /Users/zsolt/.conda/envs/tractionRheoscopy/lib/python3.7/site-packages/tornado/web.py:2333]>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.77 s, sys: 441 ms, total: 2.21 s\n",
      "Wall time: 56.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tmp_middleChunk = tmp[l[0]:r[0]+n[0],l[1]:r[1]+n[1], l[2]:r[2]+n[2]]\n",
    "chunk_da = dask.array.from_array(tmp_middleChunk,chunks=(40,46,46))\n",
    "#chunk_da\n",
    "autoCorr_3d = lambda x: slb.spatialCorr_daskWrapper(x, x, k_px.astype(int), corrFunc='forLoop', padOut=False)\n",
    "#out_chunk = autoCorr_3d(tmp_middleChunk)\n",
    "with LocalCluster(n_workers=4, threads_per_worker=6, memory_limit='2Gb') as node, Client(node) as client:\n",
    "    out_overlap3D = chunk_da.map_blocks(autoCorr_3d, dtype='float32').astype(int).compute()\n",
    "    \n",
    "# Table of results\n",
    "# 8 chunks on 8 cores, as expect 30sec\n",
    "# 8 chunks on 4 cores, as expected 56 sec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.8 s, sys: 2.67 s, total: 18.5 s\n",
      "Wall time: 5min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# lets try dask overlap, maybe thats the issue\n",
    "# 4 chunks\n",
    "_n = np.array((0,1,1)).astype(int)\n",
    "n = _n*chunk_px.astype(int)\n",
    "\n",
    "tmp_middleChunk = tmp[l[0]:r[0]+n[0],l[1]:r[1]+n[1], l[2]:r[2]+n[2]]\n",
    "chunk_da = dask.array.from_array(tmp_middleChunk,chunks=(40,46,46))\n",
    "chunk_da\n",
    "\n",
    "autoCorr_3d = lambda x: slb.spatialCorr_daskWrapper(x, x, k_px.astype(int), corrFunc='forLoop', padOut=False)\n",
    "with LocalCluster(n_workers=4, threads_per_worker=6, memory_limit='2Gb') as node, Client(node) as client:\n",
    "    out_overlap3D = chunk_da.map_overlap(autoCorr_3d, depth=20, dtype='float32',chunks=np.array((2*k_px[0]+1, 2*k_px[1]+1, 2*k_px[2]+1)).astype(int)).compute()\n",
    "    \n",
    "# resutls, 5min 47 secs. \n",
    "# Longer than I expected for a single chunk, but maybe thats becasue depth overlap is actually 20 on each side as opposed to 20 total\n",
    "# While longer than I expected, it does not explain the 24 hour run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.88 s, sys: 753 ms, total: 3.63 s\n",
      "Wall time: 51.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# lets try dask overlap, maybe thats the issue\n",
    "# 4 chunks\n",
    "_n = np.array((1,1,1)).astype(int)\n",
    "n = _n*chunk_px.astype(int)\n",
    "\n",
    "tmp_middleChunk = tmp[l[0]:r[0]+n[0],l[1]:r[1]+n[1], l[2]:r[2]+n[2]]\n",
    "chunk_da = dask.array.from_array(tmp_middleChunk,chunks=(40,46,46))\n",
    "chunk_da\n",
    "\n",
    "#from dask.diagnostics import ProgressBar\n",
    "autoCorr_3d = lambda x: slb.spatialCorr_daskWrapper(x, x, k_px.astype(int), corrFunc='forLoop', padOut=False)\n",
    "with LocalCluster(n_workers=8, threads_per_worker=6, memory_limit='2Gb') as node, Client(node) as client, ProgressBar():\n",
    "    out_overlap3D = chunk_da.map_overlap(autoCorr_3d, depth=3, dtype='float32',chunks=np.array((2*k_px[0]+1, 2*k_px[1]+1, 2*k_px[2]+1)).astype(int)).compute()\n",
    "\n",
    "# results\n",
    "# 4 chunks, depth 10, 4 cores : 1 min 51s --right in line with what a single chunk takes without dask\n",
    "# 4 chunk, depth 10, 2 cores: 3 min 21s -- better than expected, owing to less initialization time. \n",
    "# 18 chunks, depth 10, 15 cores, including f\n",
    "# 8 chunks, depth 3, 8 cores: 51 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task was destroyed but it is pending!\n",
      "task: <Task pending coro=<RequestHandler._execute() running at /Users/zsolt/.conda/envs/tractionRheoscopy/lib/python3.7/site-packages/tornado/web.py:1703> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x7f7d0824a5d0>()]> cb=[_HandlerDelegate.execute.<locals>.<lambda>() at /Users/zsolt/.conda/envs/tractionRheoscopy/lib/python3.7/site-packages/tornado/web.py:2333]>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending coro=<HTTP1ServerConnection._server_request_loop() running at /Users/zsolt/.conda/envs/tractionRheoscopy/lib/python3.7/site-packages/tornado/http1connection.py:817> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x7f7c781aaa90>()]> cb=[IOLoop.add_future.<locals>.<lambda>() at /Users/zsolt/.conda/envs/tractionRheoscopy/lib/python3.7/site-packages/tornado/ioloop.py:690]>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending coro=<RequestHandler._execute() running at /Users/zsolt/.conda/envs/tractionRheoscopy/lib/python3.7/site-packages/tornado/web.py:1703> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x7f8412723450>()]> cb=[_HandlerDelegate.execute.<locals>.<lambda>() at /Users/zsolt/.conda/envs/tractionRheoscopy/lib/python3.7/site-packages/tornado/web.py:2333]>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 7s, sys: 40.8 s, total: 5min 48s\n",
      "Wall time: 24min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tmp2 = np.zeros((120,460,460))\n",
    "tmp2[1:tmp.shape[0]+1,:,:] = tmp[:,3:tmp.shape[2]-3,3:tmp.shape[2]-3]\n",
    "tmp_da = dask.array.from_array(tmp2,chunks=(40,46,46))\n",
    "tmp_da # 300 tasks, chunk size (40,46,46) with (3,10,10) chunks\n",
    "#k_px #[18, 20, 20]\n",
    "\n",
    "autoCorr_3d = lambda x: slb.spatialCorr_daskWrapper(x, x, k_px.astype(int), corrFunc='forLoop', padOut=False)\n",
    "with LocalCluster(n_workers=15, threads_per_worker=6, memory_limit='2Gb') as node, Client(node) as client:\n",
    "    out_overlap3D = tmp_da.map_overlap(autoCorr_3d, depth=3, dtype='float32',chunks=np.array((2*k_px[0]+1, 2*k_px[1]+1, 2*k_px[2]+1)).astype(int)).compute()\n",
    "\n",
    "# results\n",
    "# my expectation is that the full image with depth 3 should take 20 min on 15 cores, actual 24 min! not bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'strainAutoCorr_exz_ref3_cur8.h5'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save to h5 file \n",
    "#import h5py\n",
    "\n",
    "corrPath = '/Volumes/TFR/tfrGel10212018A_shearRun10292018f/strainCorrelation/'\n",
    "fName_frmt = 'strainAutoCorr_{strainComp}_ref{ref}_cur{cur}.h5'\n",
    "metaData = {'strainComp':'exz', 'ref': 3, 'cur': 8}\n",
    "metaData.keys()\n",
    "fName_frmt.format(**metaData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(corrPath + fName_frmt.format('xz',3,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments \n",
    "- I think there is something I dont understand about how Dask map_overlap is working. \n",
    "- I think map_overlap shold work, maybe with a bit more overhead, just like splitting the array into overlapping   chunks and then sending each chunk to a autoCorr_3d and saving the output. \n",
    "- This is clearly not what is happening as the timing on a single chunk is 30sec-2min depending on the size of\n",
    "  of the array, while map_overlap applied to the chunks took 24 hrs and didnt finish.  \n",
    "- Should I just use multiprocessing? Or try to figure out why dask isnt working the way I expect? \n",
    "- Update: I have no idea why this didnt work with dask. It certainly seems to be working as epected for smaller test cases\n",
    "          with embarrassingly parallel scaling. \n",
    "- I am just going to try again. \n",
    "- UPDATE: I think the problem is very poor scaling with subarray size. Its best to keep the arrays small (say 50px on each side, and then scale the interpolation get longer or shorter range features...and if there is a region in shift vectors that you want high resolution (say 200nm spacing) and long range (20um) then only run the computation on the plane you're visualizing (and bite the bullet if its expensive...like a few min per k-point)\n",
    "- At that level, its probably best to parallelize the kpoint computaiton as opposed to just the region as I am currently doing with map blocks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5]),\n",
       " array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Reproduce some errors\n",
    "## Dask map blocks and map overlap really do work on a block and reassemble the result\n",
    "# so why doesn't it parallelize the way it should? It can't figure out the right steps?\n",
    "# it tries communicating? It really should be embarrassingly parallel. \n",
    "# maybe it is computing a correlation for every pair of blocks? Somehow its not a problem with map_overlap\n",
    "# but rather I need two arrays. \n",
    "# or maybe it was running block corr with whole? \n",
    "# or maybe it wasnt dealing with the boundaries incorrectly and got a few spurious, very large arrays to compute on.\n",
    "def avgBlock(block):\n",
    "    out = np.zeros_like(block)\n",
    "    for n in range(len(block)):\n",
    "        #print(n)\n",
    "        out[n] = np.mean(block[:n+1])\n",
    "    return out\n",
    "\n",
    "A = da.arange(10,chunks=5).astype('float')\n",
    "avgBlock(np.arange(10).astype('float')), np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0. , 0.5, 1. , 1.5, 2. , 5. , 5.5, 6. , 6.5, 7. ]),\n",
       " array([0.        , 0.33333333, 0.75      , 1.2       , 1.66666667,\n",
       "        4.5       , 5.        , 5.5       , 6.        , 6.5       ]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = A.map_blocks(avgBlock).compute()\n",
    "out_overlap = A.map_overlap(avgBlock,depth=1).compute()\n",
    "out,out_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 2., 3., 4., 5., 6., 3., 4., 5., 6., 7., 8., 9.]),\n",
       " dask.array<overlap, shape=(14,), dtype=float64, chunksize=(7,), chunktype=numpy.ndarray>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = da.overlap.overlap(A,depth=2,boundary='none')\n",
    "np.array(g)\n",
    "#g.map_blocks(avgBlock).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60, 66, 66), array([18., 20., 20.]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_overlap.shape, k_px\n",
    "#k_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 203.14 MB </td> <td> 677.12 kB </td></tr>\n",
       "    <tr><th> Shape </th><td> (120, 460, 460) </td> <td> (40, 46, 46) </td></tr>\n",
       "    <tr><th> Count </th><td> 300 Tasks </td><td> 300 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> float64 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"205\" height=\"195\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"35\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"12\" x2=\"35\" y2=\"37\" />\n",
       "  <line x1=\"10\" y1=\"24\" x2=\"35\" y2=\"49\" />\n",
       "  <line x1=\"10\" y1=\"36\" x2=\"35\" y2=\"61\" />\n",
       "  <line x1=\"10\" y1=\"48\" x2=\"35\" y2=\"73\" />\n",
       "  <line x1=\"10\" y1=\"60\" x2=\"35\" y2=\"85\" />\n",
       "  <line x1=\"10\" y1=\"72\" x2=\"35\" y2=\"97\" />\n",
       "  <line x1=\"10\" y1=\"84\" x2=\"35\" y2=\"109\" />\n",
       "  <line x1=\"10\" y1=\"96\" x2=\"35\" y2=\"121\" />\n",
       "  <line x1=\"10\" y1=\"108\" x2=\"35\" y2=\"133\" />\n",
       "  <line x1=\"10\" y1=\"120\" x2=\"35\" y2=\"145\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"18\" y2=\"128\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"26\" y2=\"136\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"35\" y2=\"145\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 35.32707030120929,25.32707030120929 35.32707030120929,145.3270703012093 10.0,120.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"138\" y2=\"8\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"146\" y2=\"16\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"155\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"35\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"22\" y1=\"0\" x2=\"47\" y2=\"25\" />\n",
       "  <line x1=\"34\" y1=\"0\" x2=\"59\" y2=\"25\" />\n",
       "  <line x1=\"46\" y1=\"0\" x2=\"71\" y2=\"25\" />\n",
       "  <line x1=\"58\" y1=\"0\" x2=\"83\" y2=\"25\" />\n",
       "  <line x1=\"70\" y1=\"0\" x2=\"95\" y2=\"25\" />\n",
       "  <line x1=\"82\" y1=\"0\" x2=\"107\" y2=\"25\" />\n",
       "  <line x1=\"94\" y1=\"0\" x2=\"119\" y2=\"25\" />\n",
       "  <line x1=\"106\" y1=\"0\" x2=\"131\" y2=\"25\" />\n",
       "  <line x1=\"118\" y1=\"0\" x2=\"143\" y2=\"25\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"155\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 155.3270703012093,25.32707030120929 35.32707030120929,25.32707030120929\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"155\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"35\" y1=\"37\" x2=\"155\" y2=\"37\" />\n",
       "  <line x1=\"35\" y1=\"49\" x2=\"155\" y2=\"49\" />\n",
       "  <line x1=\"35\" y1=\"61\" x2=\"155\" y2=\"61\" />\n",
       "  <line x1=\"35\" y1=\"73\" x2=\"155\" y2=\"73\" />\n",
       "  <line x1=\"35\" y1=\"85\" x2=\"155\" y2=\"85\" />\n",
       "  <line x1=\"35\" y1=\"97\" x2=\"155\" y2=\"97\" />\n",
       "  <line x1=\"35\" y1=\"109\" x2=\"155\" y2=\"109\" />\n",
       "  <line x1=\"35\" y1=\"121\" x2=\"155\" y2=\"121\" />\n",
       "  <line x1=\"35\" y1=\"133\" x2=\"155\" y2=\"133\" />\n",
       "  <line x1=\"35\" y1=\"145\" x2=\"155\" y2=\"145\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"35\" y2=\"145\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"47\" y1=\"25\" x2=\"47\" y2=\"145\" />\n",
       "  <line x1=\"59\" y1=\"25\" x2=\"59\" y2=\"145\" />\n",
       "  <line x1=\"71\" y1=\"25\" x2=\"71\" y2=\"145\" />\n",
       "  <line x1=\"83\" y1=\"25\" x2=\"83\" y2=\"145\" />\n",
       "  <line x1=\"95\" y1=\"25\" x2=\"95\" y2=\"145\" />\n",
       "  <line x1=\"107\" y1=\"25\" x2=\"107\" y2=\"145\" />\n",
       "  <line x1=\"119\" y1=\"25\" x2=\"119\" y2=\"145\" />\n",
       "  <line x1=\"131\" y1=\"25\" x2=\"131\" y2=\"145\" />\n",
       "  <line x1=\"143\" y1=\"25\" x2=\"143\" y2=\"145\" />\n",
       "  <line x1=\"155\" y1=\"25\" x2=\"155\" y2=\"145\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"35.32707030120929,25.32707030120929 155.3270703012093,25.32707030120929 155.3270703012093,145.3270703012093 35.32707030120929,145.3270703012093\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"95.327070\" y=\"165.327070\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >460</text>\n",
       "  <text x=\"175.327070\" y=\"85.327070\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,175.327070,85.327070)\">460</text>\n",
       "  <text x=\"12.663535\" y=\"152.663535\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,12.663535,152.663535)\">120</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<array, shape=(120, 460, 460), dtype=float64, chunksize=(40, 46, 46), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_zyx_interp = np.array((40,46,46))\n",
    "tmp_da = dask.array.from_array(tmp2,chunks=chunk_zyx_interp)\n",
    "tmp_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18., 20., 20.])"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This took slighly more than 24 hours and safari crashed \n",
    "# leaving the computation running but the output dangling. \n",
    "#I killed it. I suspect it would have completed in less than 36 hours, \n",
    "# however the approach needs to be updated. I am not convinced I am on the right track\n",
    "# with dask as these computations should not be taking this long on 15 cores. I assumed \n",
    "# that each chunk was sent to a core separately, but if thats true a single chunk\n",
    "# would take 15*36/300 = 1.8 hours, which seems ridiculous for an autocorrelation of a\n",
    "# matrix of 50x50x50 px over 18x20x20 shift vectors. \n",
    "# Back to the drawing board. I am going to check this explicitly without dask..amybe my \n",
    "# function really does take that long to run in which case I should switch to \n",
    "# only running autocorrelations on planes (0,ky,kx), (kz,0,kx) and (kz,ky,0) and maybe \n",
    "# some random samples elsewhere. \n",
    "# RAM usage was ok though. Maybe if there is a problem with dask, then perhaps I can just use the \n",
    "#simple multiprocessing to parallelize and\n",
    "# save the output to a list of labeled files...old school hash based parallelization.\n",
    "#\n",
    "# Suggesting that one chunk of size (40,44,40) takes about 8 min and ~500MB (<2Gb) of ram on a single thread. \n",
    "# This processes 20*20*18 = 7200 kpoints on a grid of size \n",
    "autoCorr_3d = lambda x: eshelby_inclusion.spatialCorr_daskWrapper(x, x, k_px.astype(int), corrFunc='forLoop', padOut=False)\n",
    "with LocalCluster(n_workers=15, threads_per_worker=6, memory_limit='2Gb') as node, Client(node) as client:\n",
    "    out_overlap3D = tmp_da.map_overlap(autoCorr_3d, depth=20, dtype='float32',chunks=np.array((2*k_px[0]+1, 2*k_px[1]+1, 2*k_px[2]+1)).astype(int)).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = eshelby_inclusion.spatialCorr_daskWrapper(tmp_middleChunk, tmp_middleChunk, k_px.astype(int), corrFunc='forLoop', padOut=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tmp_da' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-0448d9e49ee1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtmp_da\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tmp_da' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50, 50)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images saved to tif and copied to system clipboard.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'open(\"/Volumes/TFR/tfrGel10212018A_shearRun10292018f/pyFiji/tmp_0.tif\");\\n'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(pyFiji)\n",
    "from particleLocating import pyFiji\n",
    "tmpDir = ''\n",
    "pyFiji.send2Fiji(pyFiji.recastImage(out_overlap3D,{'min':-1.01,'max':1.01}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6012648"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize with pyfiji. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "27+55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z (um, imageStack)</th>\n",
       "      <th>y (um, imageStack)</th>\n",
       "      <th>x (um, imageStack)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>156695.000000</td>\n",
       "      <td>156695.000000</td>\n",
       "      <td>156695.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>55.414312</td>\n",
       "      <td>117.274432</td>\n",
       "      <td>117.884553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.687715</td>\n",
       "      <td>26.192660</td>\n",
       "      <td>26.226808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>27.507163</td>\n",
       "      <td>62.380020</td>\n",
       "      <td>62.960281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>42.151450</td>\n",
       "      <td>96.203895</td>\n",
       "      <td>96.823130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.066477</td>\n",
       "      <td>117.348836</td>\n",
       "      <td>117.889259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>68.356857</td>\n",
       "      <td>138.250619</td>\n",
       "      <td>139.060591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>86.964394</td>\n",
       "      <td>172.278633</td>\n",
       "      <td>172.691347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       z (um, imageStack)  y (um, imageStack)  x (um, imageStack)\n",
       "count       156695.000000       156695.000000       156695.000000\n",
       "mean            55.414312          117.274432          117.884553\n",
       "std             15.687715           26.192660           26.226808\n",
       "min             27.507163           62.380020           62.960281\n",
       "25%             42.151450           96.203895           96.823130\n",
       "50%             55.066477          117.348836          117.889259\n",
       "75%             68.356857          138.250619          139.060591\n",
       "max             86.964394          172.278633          172.691347"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.xs(0,level='frame')[posKeyList].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  1.09090909,  1.18181818,  1.27272727,  1.36363636,\n",
       "        1.45454545,  1.54545455,  1.63636364,  1.72727273,  1.81818182,\n",
       "        1.90909091,  2.        ,  2.09090909,  2.18181818,  2.27272727,\n",
       "        2.36363636,  2.45454545,  2.54545455,  2.63636364,  2.72727273,\n",
       "        2.81818182,  2.90909091,  3.        ,  3.09090909,  3.18181818,\n",
       "        3.27272727,  3.36363636,  3.45454545,  3.54545455,  3.63636364,\n",
       "        3.72727273,  3.81818182,  3.90909091,  4.        ,  4.09090909,\n",
       "        4.18181818,  4.27272727,  4.36363636,  4.45454545,  4.54545455,\n",
       "        4.63636364,  4.72727273,  4.81818182,  4.90909091,  5.        ,\n",
       "        5.09090909,  5.18181818,  5.27272727,  5.36363636,  5.45454545,\n",
       "        5.54545455,  5.63636364,  5.72727273,  5.81818182,  5.90909091,\n",
       "        6.        ,  6.09090909,  6.18181818,  6.27272727,  6.36363636,\n",
       "        6.45454545,  6.54545455,  6.63636364,  6.72727273,  6.81818182,\n",
       "        6.90909091,  7.        ,  7.09090909,  7.18181818,  7.27272727,\n",
       "        7.36363636,  7.45454545,  7.54545455,  7.63636364,  7.72727273,\n",
       "        7.81818182,  7.90909091,  8.        ,  8.09090909,  8.18181818,\n",
       "        8.27272727,  8.36363636,  8.45454545,  8.54545455,  8.63636364,\n",
       "        8.72727273,  8.81818182,  8.90909091,  9.        ,  9.09090909,\n",
       "        9.18181818,  9.27272727,  9.36363636,  9.45454545,  9.54545455,\n",
       "        9.63636364,  9.72727273,  9.81818182,  9.90909091, 10.        ])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mgrid[1:10:100j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 74955,  74956,  75057,  75063,  75068,  75071,  75078,  75079,\n",
       "             75080,  75081,\n",
       "            ...\n",
       "            890255, 890262, 890280, 890282, 890289, 890301, 890311, 890312,\n",
       "            890366, 890399],\n",
       "           dtype='int64', name='particle', length=154201)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_refConfig = pos.xs(0,level='frame').index\n",
    "idx_refConfig\n",
    "idx_traj = strain_traj.dropna().xs('exx',level='values').index.get_level_values('particle')\n",
    "idx_traj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101.0, 101.0, 101.0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2*k_px[0]+1, 2*k_px[1]+1, 2*k_px[2]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Q: does linear interpolation leaves gaps if mesh is too small?\n",
    "# A: No\n",
    "pts = [[0,0],[1,0],[0,1],[1,1]]\n",
    "vals = [-1,1,1,-1]\n",
    "grid_y, grid_x = np.mgrid[-0.1:1.1:0.1, -0.1:1.1:0.1]\n",
    "interp = griddata(pts, vals, (grid_x, grid_y), method='linear')\n",
    "\n",
    "plt.imshow(interp, interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearsonCor(A,B): return (np.mean(A * B) - np.mean(A) * np.mean(B)) / (np.sqrt(np.var(A)) * np.sqrt(np.var(B)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonCor(A,A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kx, ky = (1,-1)\n",
    "if kx > 0 and ky > 0 : a, b = A[ ky:,  kx: ], A[ :-1*ky, :-1*kx  ]\n",
    "if kx > 0 and ky < 0: a, b = A[ :ky,  kx: ], A[ -1*ky:, :-1 * kx  ]\n",
    "if kx < 0 and ky > 0: a, b = A[ ky:, :kx  ], A[ :-1*ky,  -1*kx: ]\n",
    "if kx < 0 and ky < 0 :a, b = A[ :ky, :kx  ], A[ -1*ky:,  -1 * kx: ]\n",
    "\n",
    "#a, b = A_random[ :  , :    ], A_random[ :, :         ]\n",
    "#pearsonCor(a,b)\n",
    "a_1n1, b_1n1  = a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "        [21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
       "        [31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
       "        [41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
       "        [51, 52, 53, 54, 55, 56, 57, 58, 59],\n",
       "        [61, 62, 63, 64, 65, 66, 67, 68, 69],\n",
       "        [71, 72, 73, 74, 75, 76, 77, 78, 79],\n",
       "        [81, 82, 83, 84, 85, 86, 87, 88, 89],\n",
       "        [91, 92, 93, 94, 95, 96, 97, 98, 99]]),\n",
       " array([[10, 11, 12, 13, 14, 15, 16, 17, 18],\n",
       "        [20, 21, 22, 23, 24, 25, 26, 27, 28],\n",
       "        [30, 31, 32, 33, 34, 35, 36, 37, 38],\n",
       "        [40, 41, 42, 43, 44, 45, 46, 47, 48],\n",
       "        [50, 51, 52, 53, 54, 55, 56, 57, 58],\n",
       "        [60, 61, 62, 63, 64, 65, 66, 67, 68],\n",
       "        [70, 71, 72, 73, 74, 75, 76, 77, 78],\n",
       "        [80, 81, 82, 83, 84, 85, 86, 87, 88],\n",
       "        [90, 91, 92, 93, 94, 95, 96, 97, 98]]),\n",
       " array([[ 1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "        [11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "        [21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
       "        [31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
       "        [41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
       "        [51, 52, 53, 54, 55, 56, 57, 58, 59],\n",
       "        [61, 62, 63, 64, 65, 66, 67, 68, 69],\n",
       "        [71, 72, 73, 74, 75, 76, 77, 78, 79],\n",
       "        [81, 82, 83, 84, 85, 86, 87, 88, 89]]),\n",
       " array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8],\n",
       "        [10, 11, 12, 13, 14, 15, 16, 17, 18],\n",
       "        [20, 21, 22, 23, 24, 25, 26, 27, 28],\n",
       "        [30, 31, 32, 33, 34, 35, 36, 37, 38],\n",
       "        [40, 41, 42, 43, 44, 45, 46, 47, 48],\n",
       "        [50, 51, 52, 53, 54, 55, 56, 57, 58],\n",
       "        [60, 61, 62, 63, 64, 65, 66, 67, 68],\n",
       "        [70, 71, 72, 73, 74, 75, 76, 77, 78],\n",
       "        [80, 81, 82, 83, 84, 85, 86, 87, 88]]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_11, a_n11, a_1n1,a_n1n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "        [21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
       "        [31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
       "        [41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
       "        [51, 52, 53, 54, 55, 56, 57, 58, 59],\n",
       "        [61, 62, 63, 64, 65, 66, 67, 68, 69],\n",
       "        [71, 72, 73, 74, 75, 76, 77, 78, 79],\n",
       "        [81, 82, 83, 84, 85, 86, 87, 88, 89],\n",
       "        [91, 92, 93, 94, 95, 96, 97, 98, 99]]),\n",
       " array([[10, 11, 12, 13, 14, 15, 16, 17, 18],\n",
       "        [20, 21, 22, 23, 24, 25, 26, 27, 28],\n",
       "        [30, 31, 32, 33, 34, 35, 36, 37, 38],\n",
       "        [40, 41, 42, 43, 44, 45, 46, 47, 48],\n",
       "        [50, 51, 52, 53, 54, 55, 56, 57, 58],\n",
       "        [60, 61, 62, 63, 64, 65, 66, 67, 68],\n",
       "        [70, 71, 72, 73, 74, 75, 76, 77, 78],\n",
       "        [80, 81, 82, 83, 84, 85, 86, 87, 88],\n",
       "        [90, 91, 92, 93, 94, 95, 96, 97, 98]]),\n",
       " array([[ 1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "        [11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "        [21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
       "        [31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
       "        [41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
       "        [51, 52, 53, 54, 55, 56, 57, 58, 59],\n",
       "        [61, 62, 63, 64, 65, 66, 67, 68, 69],\n",
       "        [71, 72, 73, 74, 75, 76, 77, 78, 79],\n",
       "        [81, 82, 83, 84, 85, 86, 87, 88, 89]]),\n",
       " array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8],\n",
       "        [10, 11, 12, 13, 14, 15, 16, 17, 18],\n",
       "        [20, 21, 22, 23, 24, 25, 26, 27, 28],\n",
       "        [30, 31, 32, 33, 34, 35, 36, 37, 38],\n",
       "        [40, 41, 42, 43, 44, 45, 46, 47, 48],\n",
       "        [50, 51, 52, 53, 54, 55, 56, 57, 58],\n",
       "        [60, 61, 62, 63, 64, 65, 66, 67, 68],\n",
       "        [70, 71, 72, 73, 74, 75, 76, 77, 78],\n",
       "        [80, 81, 82, 83, 84, 85, 86, 87, 88]]))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_n1n1, b_1n1, b_n11, b_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.mean(a*b) - np.mean(a)*np.mean(b))/(np.sqrt(np.var(a))*np.sqrt(np.var(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tractionRheoscopy",
   "language": "python",
   "name": "tractionrheoscopy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
